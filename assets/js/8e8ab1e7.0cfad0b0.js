"use strict";(self.webpackChunkxuecodex=self.webpackChunkxuecodex||[]).push([[5168],{6036:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>o,contentTitle:()=>a,default:()=>d,frontMatter:()=>l,metadata:()=>s,toc:()=>h});const s=JSON.parse('{"id":"topics/deep-learning/nlp/attentoin-mechanism","title":"Attention Mechanism \u2014 A Gentle but Deep Dive","description":"1\ufe0f\u20e3 What Is the Attention Mechanism and Why Is It Important?","source":"@site/docs/topics/deep-learning/nlp/attention-mechanism.md","sourceDirName":"topics/deep-learning/nlp","slug":"/topics/deep-learning/nlp/attentoin-mechanism","permalink":"/docs/topics/deep-learning/nlp/attentoin-mechanism","draft":false,"unlisted":false,"editUrl":"https://github.com/vlakmaker/XueCodex/tree/main/docs/topics/deep-learning/nlp/attention-mechanism.md","tags":[{"inline":true,"label":"transformers","permalink":"/docs/tags/transformers"},{"inline":true,"label":"nlp","permalink":"/docs/tags/nlp"},{"inline":true,"label":"neural networks","permalink":"/docs/tags/neural-networks"}],"version":"current","frontMatter":{"id":"attentoin-mechanism","title":"Attention Mechanism \u2014 A Gentle but Deep Dive","tags":["transformers","nlp","neural networks"]},"sidebar":"tutorialSidebar","previous":{"title":"What are Neural Networks?","permalink":"/docs/topics/deep-learning/neural-networks/neural-networks"},"next":{"title":"Language as a Bag-of-Words","permalink":"/docs/topics/deep-learning/nlp/bag-of-words"}}');var i=n(4848),r=n(8453);const l={id:"attentoin-mechanism",title:"Attention Mechanism \u2014 A Gentle but Deep Dive",tags:["transformers","nlp","neural networks"]},a="\ud83e\udde0 Attention Mechanism \u2014 A Gentle but Deep Dive",o={},h=[{value:"1\ufe0f\u20e3 What Is the Attention Mechanism and Why Is It Important?",id:"1\ufe0f\u20e3-what-is-the-attention-mechanism-and-why-is-it-important",level:2},{value:"2\ufe0f\u20e3 Illustrating Attention With a Translation Example",id:"2\ufe0f\u20e3-illustrating-attention-with-a-translation-example",level:2},{value:"3\ufe0f\u20e3 What\u2019s the Formula?",id:"3\ufe0f\u20e3-whats-the-formula",level:2},{value:"4\ufe0f\u20e3 What Is Softmax?",id:"4\ufe0f\u20e3-what-is-softmax",level:2},{value:"Example:",id:"example",level:3},{value:"5\ufe0f\u20e3 Mini Practicum \u2013 Let\u2019s See It Work (Conceptually)",id:"5\ufe0f\u20e3-mini-practicum--lets-see-it-work-conceptually",level:2},{value:"Step 1: Calculate Dot Product (Q \xd7 K\u1d40)",id:"step-1-calculate-dot-product-q--k\u1d40",level:3},{value:"Step 2: Apply Softmax",id:"step-2-apply-softmax",level:3},{value:"Step 3: Weighted Sum With Value Matrix",id:"step-3-weighted-sum-with-value-matrix",level:3}];function c(e){const t={blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.header,{children:(0,i.jsx)(t.h1,{id:"-attention-mechanism--a-gentle-but-deep-dive",children:"\ud83e\udde0 Attention Mechanism \u2014 A Gentle but Deep Dive"})}),"\n",(0,i.jsx)(t.h2,{id:"1\ufe0f\u20e3-what-is-the-attention-mechanism-and-why-is-it-important",children:"1\ufe0f\u20e3 What Is the Attention Mechanism and Why Is It Important?"}),"\n",(0,i.jsxs)(t.p,{children:["In human conversations, we don\u2019t focus on everything we hear at once. We ",(0,i.jsx)(t.strong,{children:"attend"})," to specific words depending on context. Language models inspired by this human ability use the ",(0,i.jsx)(t.strong,{children:"attention mechanism"})," to do something similar:"]}),"\n",(0,i.jsxs)(t.blockquote,{children:["\n",(0,i.jsx)(t.p,{children:"Attention helps the model decide what parts of the input to focus on when generating an output."}),"\n"]}),"\n",(0,i.jsx)(t.p,{children:"This is especially critical in tasks like:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Translation"}),": Knowing which source words align with each output word"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Summarization"}),": Prioritizing important parts"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Text generation"}),": Retaining context over long sequences"]}),"\n"]}),"\n",(0,i.jsxs)(t.p,{children:["Traditional models like RNNs and LSTMs struggle to remember long-range dependencies. Attention mechanisms allow even short models to access ",(0,i.jsx)(t.strong,{children:"any token at any position"})," directly."]}),"\n",(0,i.jsx)(t.hr,{}),"\n",(0,i.jsx)(t.h2,{id:"2\ufe0f\u20e3-illustrating-attention-with-a-translation-example",children:"2\ufe0f\u20e3 Illustrating Attention With a Translation Example"}),"\n",(0,i.jsx)(t.p,{children:"Let\u2019s say we want to translate the French phrase:"}),"\n",(0,i.jsx)(t.p,{children:'\ud83d\udde3\ufe0f "sous la table" \u2192 "under the table"'}),"\n",(0,i.jsxs)(t.p,{children:["The model uses a ",(0,i.jsx)(t.strong,{children:"query"})," to look for ",(0,i.jsx)(t.strong,{children:"matches (keys)"})," and retrieve associated ",(0,i.jsx)(t.strong,{children:"values"}),". It\u2019s like looking up a dictionary:"]}),"\n",(0,i.jsxs)(t.table,{children:[(0,i.jsx)(t.thead,{children:(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.th,{children:"French Word (Key)"}),(0,i.jsx)(t.th,{children:"English Word (Value)"})]})}),(0,i.jsxs)(t.tbody,{children:[(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"chat"}),(0,i.jsx)(t.td,{children:"cat"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"est"}),(0,i.jsx)(t.td,{children:"is"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"sous"}),(0,i.jsx)(t.td,{children:"under"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"la"}),(0,i.jsx)(t.td,{children:"the"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"table"}),(0,i.jsx)(t.td,{children:"table"})]})]})]}),"\n",(0,i.jsxs)(t.p,{children:["Let\u2019s say we\u2019re translating ",(0,i.jsx)(t.strong,{children:'"sous"'}),". We compare its ",(0,i.jsx)(t.strong,{children:"query"})," vector to all ",(0,i.jsx)(t.strong,{children:"key"}),' vectors (French words) using dot products. The highest match (i.e., dot product score) will be with the key for "sous", so we fetch the corresponding ',(0,i.jsx)(t.strong,{children:"value"}),' = "under".']}),"\n",(0,i.jsx)(t.hr,{}),"\n",(0,i.jsx)(t.h2,{id:"3\ufe0f\u20e3-whats-the-formula",children:"3\ufe0f\u20e3 What\u2019s the Formula?"}),"\n",(0,i.jsx)(t.p,{children:"The classic attention mechanism uses the following formula:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{children:"Attention(Q, K, V) = softmax(Q \xd7 K\u1d40) \xd7 V\n"})}),"\n",(0,i.jsx)(t.p,{children:"Where:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"Q"})," = query matrix"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"K\u1d40"})," = ",(0,i.jsx)(t.strong,{children:"transposed"})," key matrix (to align shapes for dot product)"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"V"})," = value matrix"]}),"\n"]}),"\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"Step-by-step"}),":"]}),"\n",(0,i.jsxs)(t.ol,{children:["\n",(0,i.jsxs)(t.li,{children:["Dot product between ",(0,i.jsx)(t.code,{children:"Q"})," and ",(0,i.jsx)(t.code,{children:"K\u1d40"})," gives ",(0,i.jsx)(t.strong,{children:"match scores"})]}),"\n",(0,i.jsxs)(t.li,{children:["Apply ",(0,i.jsx)(t.code,{children:"softmax"})," to turn those scores into a ",(0,i.jsx)(t.strong,{children:"probability distribution"})," (called weights)"]}),"\n",(0,i.jsxs)(t.li,{children:["Multiply weights with ",(0,i.jsx)(t.code,{children:"V"})," to get the final ",(0,i.jsx)(t.strong,{children:"output vector"})]}),"\n"]}),"\n",(0,i.jsxs)(t.blockquote,{children:["\n",(0,i.jsx)(t.p,{children:"\u2705 This lets the model retrieve a blended representation of values, based on how strongly each key matches the query."}),"\n"]}),"\n",(0,i.jsx)(t.hr,{}),"\n",(0,i.jsx)(t.h2,{id:"4\ufe0f\u20e3-what-is-softmax",children:"4\ufe0f\u20e3 What Is Softmax?"}),"\n",(0,i.jsxs)(t.p,{children:["The ",(0,i.jsx)(t.strong,{children:"softmax"})," function takes a list of numbers and turns them into a probability distribution (all values add up to 1). It boosts the biggest number and shrinks the rest."]}),"\n",(0,i.jsx)(t.h3,{id:"example",children:"Example:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{children:"Input scores: [2.0, 1.0, 0.1]\nSoftmax \u2192 [0.71, 0.26, 0.03]\n"})}),"\n",(0,i.jsx)(t.p,{children:"The biggest input gets the most weight."}),"\n",(0,i.jsx)(t.p,{children:"In attention:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:'If "sous" matches most with the key for "sous", its weight will be high.'}),"\n",(0,i.jsx)(t.li,{children:"The softmax makes sure all weights are non-negative and sum to 1."}),"\n"]}),"\n",(0,i.jsx)(t.hr,{}),"\n",(0,i.jsx)(t.h2,{id:"5\ufe0f\u20e3-mini-practicum--lets-see-it-work-conceptually",children:"5\ufe0f\u20e3 Mini Practicum \u2013 Let\u2019s See It Work (Conceptually)"}),"\n",(0,i.jsx)(t.p,{children:"Let\u2019s say:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:'Q = query for "sous"'}),"\n",(0,i.jsx)(t.li,{children:"K = matrix of keys (chat, est, sous, la, table)"}),"\n",(0,i.jsx)(t.li,{children:"V = matrix of English values (cat, is, under, the, table)"}),"\n"]}),"\n",(0,i.jsx)(t.h3,{id:"step-1-calculate-dot-product-q--k\u1d40",children:"Step 1: Calculate Dot Product (Q \xd7 K\u1d40)"}),"\n",(0,i.jsx)(t.p,{children:'You get a score for how well "sous" matches each key.'}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{children:'[0.1, 0.2, **1.5**, 0.1, 0.0]  \u2190 highest match is "sous"\n'})}),"\n",(0,i.jsx)(t.h3,{id:"step-2-apply-softmax",children:"Step 2: Apply Softmax"}),"\n",(0,i.jsx)(t.p,{children:"Turns those into weights:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{children:"[0.05, 0.07, **0.8**, 0.05, 0.03]\n"})}),"\n",(0,i.jsx)(t.h3,{id:"step-3-weighted-sum-with-value-matrix",children:"Step 3: Weighted Sum With Value Matrix"}),"\n",(0,i.jsx)(t.p,{children:"Now multiply these weights with the values:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{children:"0.05\xd7cat + 0.07\xd7is + 0.8\xd7under + 0.05\xd7the + 0.03\xd7table\n"})}),"\n",(0,i.jsx)(t.p,{children:'\ud83c\udfaf Result = a vector close to the meaning of "under"'}),"\n",(0,i.jsx)(t.p,{children:"This vector is now passed to the decoder to generate the correct translated word!"})]})}function d(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},8453:(e,t,n)=>{n.d(t,{R:()=>l,x:()=>a});var s=n(6540);const i={},r=s.createContext(i);function l(e){const t=s.useContext(r);return s.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:l(e.components),s.createElement(r.Provider,{value:t},e.children)}}}]);