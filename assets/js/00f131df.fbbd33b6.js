"use strict";(self.webpackChunkxuecodex=self.webpackChunkxuecodex||[]).push([[82],{3122:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>s,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"topics/machine-learning/training-practices/f-b-propagation","title":"Training a Neural Network: Forward and Backpropagation","description":"\ud83d\udfe2 Forward Propagation (Forward Pass)","source":"@site/docs/topics/machine-learning/training-practices/f-b-propagation.md","sourceDirName":"topics/machine-learning/training-practices","slug":"/topics/machine-learning/training-practices/f-b-propagation","permalink":"/docs/topics/machine-learning/training-practices/f-b-propagation","draft":false,"unlisted":false,"editUrl":"https://github.com/vlakmaker/XueCodex/tree/main/docs/topics/machine-learning/training-practices/f-b-propagation.md","tags":[{"inline":true,"label":"machine-learning","permalink":"/docs/tags/machine-learning"},{"inline":true,"label":"logistic regression","permalink":"/docs/tags/logistic-regression"},{"inline":true,"label":"deep learning","permalink":"/docs/tags/deep-learning"}],"version":"current","frontMatter":{"id":"f-b-propagation","title":"Training a Neural Network: Forward and Backpropagation","tags":["machine-learning","logistic regression","deep learning"]},"sidebar":"tutorialSidebar","previous":{"title":"Vectorizing Logistic Regression","permalink":"/docs/topics/machine-learning/logistic-regression/vectorizing-logistic-regression"},"next":{"title":"Understanding the Training Process of a Machine Learning Model","permalink":"/docs/topics/machine-learning/training-practices/training-process-of-ml"}}');var a=i(4848),t=i(8453);const s={id:"f-b-propagation",title:"Training a Neural Network: Forward and Backpropagation",tags:["machine-learning","logistic regression","deep learning"]},o="\ud83e\udde0 Training a Neural Network: Forward and Backpropagation",l={},c=[{value:"\ud83d\udfe2 Forward Propagation (Forward Pass)",id:"-forward-propagation-forward-pass",level:2},{value:"\ud83d\udd0d How it works:",id:"-how-it-works",level:3},{value:"\ud83d\udce6 Analogy:",id:"-analogy",level:3},{value:"\ud83d\udd34 Backpropagation (Backward Pass)",id:"-backpropagation-backward-pass",level:2},{value:"\ud83d\udd0d How it works:",id:"-how-it-works-1",level:3},{value:"\ud83d\udce6 Analogy:",id:"-analogy-1",level:3},{value:"\ud83d\udd01 The Full Training Loop:",id:"-the-full-training-loop",level:2},{value:"\ud83e\udde0 Why It Matters",id:"-why-it-matters",level:2}];function d(n){const e={blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,t.R)(),...n.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.header,{children:(0,a.jsx)(e.h1,{id:"-training-a-neural-network-forward-and-backpropagation",children:"\ud83e\udde0 Training a Neural Network: Forward and Backpropagation"})}),"\n",(0,a.jsx)(e.h2,{id:"-forward-propagation-forward-pass",children:"\ud83d\udfe2 Forward Propagation (Forward Pass)"}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Forward propagation"})," is how a neural network takes input and produces an output by passing data through layers."]}),"\n",(0,a.jsx)(e.h3,{id:"-how-it-works",children:"\ud83d\udd0d How it works:"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsxs)(e.li,{children:["Take input data (e.g., features like ",(0,a.jsx)(e.code,{children:"a"}),", ",(0,a.jsx)(e.code,{children:"b"}),", ",(0,a.jsx)(e.code,{children:"c"}),")"]}),"\n",(0,a.jsx)(e.li,{children:"Multiply each input by a weight, add a bias"}),"\n",(0,a.jsxs)(e.li,{children:["Apply an ",(0,a.jsx)(e.strong,{children:"activation function"})," (like sigmoid, ReLU)"]}),"\n",(0,a.jsx)(e.li,{children:"Pass the result forward to the next layer"}),"\n",(0,a.jsx)(e.li,{children:"At the final layer, output a prediction (like spam/not spam)"}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"-analogy",children:"\ud83d\udce6 Analogy:"}),"\n",(0,a.jsxs)(e.blockquote,{children:["\n",(0,a.jsx)(e.p,{children:"Think of it like a smoothie blender:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Ingredients = input data"}),"\n",(0,a.jsx)(e.li,{children:"Blending = math through layers"}),"\n",(0,a.jsx)(e.li,{children:"Smoothie = output prediction"}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(e.hr,{}),"\n",(0,a.jsx)(e.h2,{id:"-backpropagation-backward-pass",children:"\ud83d\udd34 Backpropagation (Backward Pass)"}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Backpropagation"})," is how the network learns from its mistakes. It works backward from the output to update the weights."]}),"\n",(0,a.jsx)(e.h3,{id:"-how-it-works-1",children:"\ud83d\udd0d How it works:"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:["After forward pass, compare the prediction with the correct label using a ",(0,a.jsx)(e.strong,{children:"loss function"})]}),"\n",(0,a.jsx)(e.p,{children:'Example: "The model predicted 0.8 but the real label was 1"'}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:["Compute the ",(0,a.jsx)(e.strong,{children:"error"})," (cost or loss)"]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:["Use ",(0,a.jsx)(e.strong,{children:"derivatives"})," to calculate how much each weight contributed to the error"]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:["Update the weights using ",(0,a.jsx)(e.strong,{children:"gradient descent"})," to reduce the error next time"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"-analogy-1",children:"\ud83d\udce6 Analogy:"}),"\n",(0,a.jsxs)(e.blockquote,{children:["\n",(0,a.jsx)(e.p,{children:"Like throwing a ball at a target:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"You throw it (forward pass)"}),"\n",(0,a.jsx)(e.li,{children:"See where it landed (loss)"}),"\n",(0,a.jsx)(e.li,{children:"Adjust your aim (backpropagation)"}),"\n",(0,a.jsx)(e.li,{children:"Try again with improvement (gradient descent)"}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(e.hr,{}),"\n",(0,a.jsx)(e.h2,{id:"-the-full-training-loop",children:"\ud83d\udd01 The Full Training Loop:"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Forward Propagation"}),": Make prediction"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Loss Function"}),": Measure how wrong it was"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Backpropagation"}),": Calculate how to fix weights"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Gradient Descent"}),": Update weights"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Repeat"})," until the model learns"]}),"\n"]}),"\n",(0,a.jsx)(e.hr,{}),"\n",(0,a.jsx)(e.h2,{id:"-why-it-matters",children:"\ud83e\udde0 Why It Matters"}),"\n",(0,a.jsx)(e.p,{children:"This loop \u2014 forward pass + backward pass \u2014 is how deep learning models learn over time."}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:["Forward pass is ",(0,a.jsx)(e.strong,{children:"inference"})]}),"\n",(0,a.jsxs)(e.li,{children:["Backward pass is ",(0,a.jsx)(e.strong,{children:"learning"})]}),"\n"]}),"\n",(0,a.jsx)(e.p,{children:"Together, they train models to recognize patterns, minimize error, and improve performance."})]})}function h(n={}){const{wrapper:e}={...(0,t.R)(),...n.components};return e?(0,a.jsx)(e,{...n,children:(0,a.jsx)(d,{...n})}):d(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>s,x:()=>o});var r=i(6540);const a={},t=r.createContext(a);function s(n){const e=r.useContext(t);return r.useMemo((function(){return"function"==typeof n?n(e):{...e,...n}}),[e,n])}function o(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(a):n.components||a:s(n.components),r.createElement(t.Provider,{value:e},n.children)}}}]);