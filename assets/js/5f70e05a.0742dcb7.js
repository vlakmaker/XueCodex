"use strict";(self.webpackChunkxuecodex=self.webpackChunkxuecodex||[]).push([[6278],{6778:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>l,default:()=>h,frontMatter:()=>a,metadata:()=>i,toc:()=>o});const i=JSON.parse('{"id":"topics/deep-learning/nlp/rag-introduction","title":"rag-introduction","description":"---","source":"@site/docs/topics/deep-learning/nlp/rag-introduction.md","sourceDirName":"topics/deep-learning/nlp","slug":"/topics/deep-learning/nlp/rag-introduction","permalink":"/docs/topics/deep-learning/nlp/rag-introduction","draft":false,"unlisted":false,"editUrl":"https://github.com/vlakmaker/XueCodex/tree/main/docs/topics/deep-learning/nlp/rag-introduction.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Converting Words to Features in NLP","permalink":"/docs/topics/deep-learning/nlp/convert-words-features"},"next":{"title":"Word Embeddings & Sequence Models in NLP","permalink":"/docs/topics/deep-learning/nlp/word-embeddings"}}');var r=t(4848),s=t(8453);const a={},l=void 0,d={},o=[{value:"id: rag-intro\ntitle: Introduction to Retrieval-Augmented Generation (RAG)\nsidebar_label: Retrieval-Augmented Generation (RAG)\ntags: [RAG, LLM, AI Engineering, LangChain, Vector DB]\ndescription: A comprehensive guide to understanding and applying Retrieval-Augmented Generation (RAG) systems, with practical insights for creative builders like Veer.",id:"id-rag-introtitle-introduction-to-retrieval-augmented-generation-ragsidebar_label-retrieval-augmented-generation-ragtags-rag-llm-ai-engineering-langchain-vector-dbdescription-a-comprehensive-guide-to-understanding-and-applying-retrieval-augmented-generation-rag-systems-with-practical-insights-for-creative-builders-like-veer",level:2},{value:"\u2728 Overview",id:"-overview",level:2},{value:"\ud83e\uddf1 RAG System Architecture (4 Main Stages)",id:"-rag-system-architecture-4-main-stages",level:2},{value:"\ud83d\udcac Key Concepts",id:"-key-concepts",level:2},{value:"\ud83e\udd14 Why Use RAG?",id:"-why-use-rag",level:2},{value:"\u26a0\ufe0f RAG Limitations &amp; Trade-offs",id:"\ufe0f-rag-limitations--trade-offs",level:2},{value:"\ud83e\uddea Real-World Use Case: MythosQuest\u2019s RAG Potential",id:"-real-world-use-case-mythosquests-rag-potential",level:2},{value:"\ud83d\udd39 What Makes It RAG-Ready:",id:"-what-makes-it-rag-ready",level:3},{value:"\ud83d\udd39 Possible Implementations:",id:"-possible-implementations",level:3},{value:"\ud83d\udd39 Future RAG Features:",id:"-future-rag-features",level:3},{value:"\ud83e\udde0 Analogy",id:"-analogy",level:2},{value:"\ud83d\udee0 Tools &amp; Tech Stack",id:"-tools--tech-stack",level:2},{value:"\ud83d\uddfa\ufe0f Learning Path for RAG",id:"\ufe0f-learning-path-for-rag",level:2},{value:"\u2705 Self-Test Questions",id:"-self-test-questions",level:2}];function c(e){const n={code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",hr:"hr",li:"li",ol:"ol",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"id-rag-introtitle-introduction-to-retrieval-augmented-generation-ragsidebar_label-retrieval-augmented-generation-ragtags-rag-llm-ai-engineering-langchain-vector-dbdescription-a-comprehensive-guide-to-understanding-and-applying-retrieval-augmented-generation-rag-systems-with-practical-insights-for-creative-builders-like-veer",children:"id: rag-intro\ntitle: Introduction to Retrieval-Augmented Generation (RAG)\nsidebar_label: Retrieval-Augmented Generation (RAG)\ntags: [RAG, LLM, AI Engineering, LangChain, Vector DB]\ndescription: A comprehensive guide to understanding and applying Retrieval-Augmented Generation (RAG) systems, with practical insights for creative builders like Veer."}),"\n",(0,r.jsx)(n.h1,{id:"-retrieval-augmented-generation-rag",children:"\ud83e\udde0 Retrieval-Augmented Generation (RAG)"}),"\n",(0,r.jsx)(n.h2,{id:"-overview",children:"\u2728 Overview"}),"\n",(0,r.jsxs)(n.p,{children:["Retrieval-Augmented Generation (RAG) is a powerful AI pattern designed to make language models ",(0,r.jsx)(n.strong,{children:"more accurate, more up-to-date, and less prone to hallucination"})," by augmenting their responses with external information at runtime."]}),"\n",(0,r.jsxs)(n.p,{children:["Unlike fine-tuning a model on custom data\u2014which is static, costly, and harder to update\u2014RAG keeps your base model untouched and instead ",(0,r.jsx)(n.strong,{children:"injects context dynamically"})," through a retrieval step. This makes it ",(0,r.jsx)(n.strong,{children:"modular, explainable, and efficient"}),"."]}),"\n",(0,r.jsxs)(n.p,{children:["RAG is at the core of many production-grade LLM applications: internal knowledge assistants, document Q&A tools, chatbots grounded in policy documents, or even personal productivity agents. For applied AI builders like you, Veer, it\u2019s a ",(0,r.jsx)(n.strong,{children:"foundational skillset"})," to bridge AI and real-world use cases."]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"-rag-system-architecture-4-main-stages",children:"\ud83e\uddf1 RAG System Architecture (4 Main Stages)"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Stage"}),(0,r.jsx)(n.th,{children:"What It Does"}),(0,r.jsx)(n.th,{children:"Example"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"1. Ingestion"})}),(0,r.jsx)(n.td,{children:"Chunks documents and turns them into vector embeddings"}),(0,r.jsx)(n.td,{children:"Splitting a company handbook into 500-token sections and embedding them"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"2. Retrieval"})}),(0,r.jsx)(n.td,{children:"Transforms the user\u2019s query into an embedding, then finds semantically similar chunks"}),(0,r.jsx)(n.td,{children:"User asks: \u201cWhat\u2019s our refund policy?\u201d \u2192 retrieves relevant sections"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"3. Augmentation"})}),(0,r.jsx)(n.td,{children:"Combines the user query and retrieved chunks into a single prompt"}),(0,r.jsx)(n.td,{children:"The final prompt includes context + question"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"4. Generation"})}),(0,r.jsx)(n.td,{children:"The LLM generates an answer based on the enriched prompt"}),(0,r.jsx)(n.td,{children:'"According to company policy, refunds are issued within 30 days..."'})]})]})]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"-key-concepts",children:"\ud83d\udcac Key Concepts"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Embedding"}),": Turning text into high-dimensional vectors to enable similarity search."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Vector Database"}),": A specialized database (like FAISS, Pinecone, Weaviate) that indexes embeddings."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Chunking"}),": Splitting large documents into smaller units to optimize semantic retrieval."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Prompt Augmentation"}),": The process of injecting retrieved content into the LLM\u2019s input prompt."]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"-why-use-rag",children:"\ud83e\udd14 Why Use RAG?"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Benefit"}),(0,r.jsx)(n.th,{children:"Description"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"\u2705 Reduces hallucinations"}),(0,r.jsx)(n.td,{children:"Grounds answers in trusted data"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"\ud83d\udd01 Dynamic & updatable"}),(0,r.jsx)(n.td,{children:"New data can be added instantly"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"\ud83d\udcb8 Cost-effective"}),(0,r.jsx)(n.td,{children:"No need for expensive fine-tuning"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"\ud83e\udde0 Domain adaptation"}),(0,r.jsx)(n.td,{children:"Inject domain-specific knowledge at inference time"})]})]})]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"\ufe0f-rag-limitations--trade-offs",children:"\u26a0\ufe0f RAG Limitations & Trade-offs"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Retrieval errors can mislead the LLM"}),"\n",(0,r.jsx)(n.li,{children:"Limited by the context window of the model"}),"\n",(0,r.jsx)(n.li,{children:"Chunking must balance size vs relevance"}),"\n",(0,r.jsx)(n.li,{children:"The model can still hallucinate if prompted poorly"}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"-real-world-use-case-mythosquests-rag-potential",children:"\ud83e\uddea Real-World Use Case: MythosQuest\u2019s RAG Potential"}),"\n",(0,r.jsxs)(n.p,{children:["Your ",(0,r.jsx)(n.strong,{children:"MythosQuest"})," project is a perfect candidate for a custom RAG pipeline. With its narrative-driven structure, modular lore elements, and need for dynamic, accurate, context-aware generation, RAG could empower the experience in several ways:"]}),"\n",(0,r.jsx)(n.h3,{id:"-what-makes-it-rag-ready",children:"\ud83d\udd39 What Makes It RAG-Ready:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Structured content: Character bios, timelines, locations, and factions are modular"}),"\n",(0,r.jsx)(n.li,{children:"Needs consistency: RAG can help the LLM respect world logic and continuity"}),"\n",(0,r.jsx)(n.li,{children:"Replayability: Personalized memory and knowledge injection per session"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"-possible-implementations",children:"\ud83d\udd39 Possible Implementations:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Embed lore files and store in FAISS or Chroma"}),"\n",(0,r.jsx)(n.li,{children:"Retrieve relevant facts per player prompt (\u201cWho are the von Trauns?\u201d)"}),"\n",(0,r.jsx)(n.li,{children:"Inject context into generation to maintain immersion and consistency"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"-future-rag-features",children:"\ud83d\udd39 Future RAG Features:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Allow player-created artifacts to be embedded into the system"}),"\n",(0,r.jsx)(n.li,{children:"Track semantic memories and consequences across play sessions"}),"\n",(0,r.jsx)(n.li,{children:"Add a reranker or feedback mechanism to improve retrieval relevance"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["> \ud83d\udca1 Think of MythosQuest RAG as a ",(0,r.jsx)(n.strong,{children:"dynamic lore oracle"})," \u2014 instead of hardcoding paths, you let players explore your world and the AI ",(0,r.jsx)(n.em,{children:"remembers where they\u2019ve been."})]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"-analogy",children:"\ud83e\udde0 Analogy"}),"\n",(0,r.jsxs)(n.p,{children:["> RAG is like giving your LLM a ",(0,r.jsx)(n.strong,{children:"magic backpack full of scrolls"})," before answering. Without it, it guesses. With it, it reads first\u2014then answers smartly."]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"-tools--tech-stack",children:"\ud83d\udee0 Tools & Tech Stack"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Component"}),(0,r.jsx)(n.th,{children:"Tools & Options"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Embedding Models"}),(0,r.jsxs)(n.td,{children:["OpenAI (",(0,r.jsx)(n.code,{children:"text-embedding-ada"}),"), Cohere, HuggingFace"]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Vector Stores"}),(0,r.jsx)(n.td,{children:"FAISS, Pinecone, ChromaDB, Weaviate"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Frameworks"}),(0,r.jsx)(n.td,{children:"LangChain, Haystack"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"LLMs"}),(0,r.jsx)(n.td,{children:"OpenAI, Claude, Mistral, Ollama"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Infra/Glue"}),(0,r.jsx)(n.td,{children:"Docker, FastAPI, GitHub Actions, Cloud/VPS"})]})]})]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"\ufe0f-learning-path-for-rag",children:"\ud83d\uddfa\ufe0f Learning Path for RAG"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Phase"}),(0,r.jsx)(n.th,{children:"Goal"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"\ud83e\udde0 Understand"}),(0,r.jsx)(n.td,{children:"Know how RAG components work together"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"\u2699\ufe0f Prototype"}),(0,r.jsx)(n.td,{children:"Build a small RAG system (e.g., Notion Q&A or lore bot)"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"\ud83d\udcda Apply"}),(0,r.jsx)(n.td,{children:"Add RAG to MythosQuest or similar projects"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"\ud83d\ude80 Expand"}),(0,r.jsx)(n.td,{children:"Implement reranking, feedback loops, memory"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"\ud83e\uddea Evaluate"}),(0,r.jsx)(n.td,{children:"Measure retrieval quality and output trustworthiness"})]})]})]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"-self-test-questions",children:"\u2705 Self-Test Questions"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"What are the four stages of a RAG pipeline?"}),"\n",(0,r.jsx)(n.li,{children:"How does RAG differ from fine-tuning?"}),"\n",(0,r.jsx)(n.li,{children:"What happens if chunking is too large or too small?"}),"\n",(0,r.jsx)(n.li,{children:"Why is retrieval quality critical to RAG success?"}),"\n",(0,r.jsx)(n.li,{children:"How could you implement RAG in your current projects?"}),"\n"]}),"\n",(0,r.jsx)(n.hr,{})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>l});var i=t(6540);const r={},s=i.createContext(r);function a(e){const n=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);