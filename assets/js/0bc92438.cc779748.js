"use strict";(self.webpackChunkxuecodex=self.webpackChunkxuecodex||[]).push([[3350],{3251:(s,e,n)=>{n.r(e),n.d(e,{assets:()=>c,contentTitle:()=>r,default:()=>m,frontMatter:()=>i,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"topics/deep-learning/nlp/Multi-head attention","title":"Multihead Attention","description":"\ud83e\udde0 1. What Is Scaled Dot-Product Attention?","source":"@site/docs/topics/deep-learning/nlp/multi-head-attention.md","sourceDirName":"topics/deep-learning/nlp","slug":"/topics/deep-learning/nlp/Multi-head attention","permalink":"/docs/topics/deep-learning/nlp/Multi-head attention","draft":false,"unlisted":false,"editUrl":"https://github.com/vlakmaker/XueCodex/tree/main/docs/topics/deep-learning/nlp/multi-head-attention.md","tags":[{"inline":true,"label":"transformers","permalink":"/docs/tags/transformers"},{"inline":true,"label":"nlp","permalink":"/docs/tags/nlp"},{"inline":true,"label":"neural networks","permalink":"/docs/tags/neural-networks"}],"version":"current","frontMatter":{"id":"Multi-head attention","title":"Multihead Attention","tags":["transformers","nlp","neural networks"]},"sidebar":"tutorialSidebar","previous":{"title":"Language AI Tasks (NLP Task Overview)","permalink":"/docs/topics/deep-learning/nlp/language-ai-tasks"},"next":{"title":"positional-encoding","permalink":"/docs/topics/deep-learning/nlp/positional-encoding"}}');var a=n(4848),l=n(8453);const i={id:"Multi-head attention",title:"Multihead Attention",tags:["transformers","nlp","neural networks"]},r=void 0,c={},d=[{value:"\ud83e\udde0 1. What Is Scaled Dot-Product Attention?",id:"-1-what-is-scaled-dot-product-attention",level:2},{value:"Meaning of terms:",id:"meaning-of-terms",level:3},{value:"\ud83d\udd01 2. What Is Multi-Head Attention?",id:"-2-what-is-multi-head-attention",level:2},{value:"Example:",id:"example",level:3},{value:"\ud83c\udfd7\ufe0f 3. What\u2019s a Transformer Encoder Layer?",id:"\ufe0f-3-whats-a-transformer-encoder-layer",level:2},{value:"\ud83e\udde9 4. What About Transformers for Translation?",id:"-4-what-about-transformers-for-translation",level:2},{value:"Decoder Specialties:",id:"decoder-specialties",level:3},{value:"\ud83d\udd27 5. How Do You Build This in PyTorch?",id:"-5-how-do-you-build-this-in-pytorch",level:2},{value:"Multihead Attention",id:"multihead-attention",level:3},{value:"\ud83c\udfaf 6. Recap",id:"-6-recap",level:2}];function h(s){const e={annotation:"annotation",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",hr:"hr",li:"li",math:"math",mfrac:"mfrac",mi:"mi",mo:"mo",mrow:"mrow",msqrt:"msqrt",msub:"msub",msup:"msup",mtext:"mtext",ol:"ol",p:"p",path:"path",semantics:"semantics",span:"span",strong:"strong",svg:"svg",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,l.R)(),...s.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.h2,{id:"-1-what-is-scaled-dot-product-attention",children:"\ud83e\udde0 1. What Is Scaled Dot-Product Attention?"}),"\n",(0,a.jsx)(e.p,{children:"At its core, attention is about:"}),"\n",(0,a.jsxs)(e.blockquote,{children:["\n",(0,a.jsx)(e.p,{children:'"How much should I focus on each word in the input?"'}),"\n"]}),"\n",(0,a.jsxs)(e.p,{children:["The ",(0,a.jsx)(e.strong,{children:"scaled dot-product attention"})," formula is:"]}),"\n",(0,a.jsx)(e.span,{className:"katex-display",children:(0,a.jsxs)(e.span,{className:"katex",children:[(0,a.jsx)(e.span,{className:"katex-mathml",children:(0,a.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block",children:(0,a.jsxs)(e.semantics,{children:[(0,a.jsxs)(e.mrow,{children:[(0,a.jsx)(e.mtext,{children:"Attention"}),(0,a.jsx)(e.mo,{stretchy:"false",children:"("}),(0,a.jsx)(e.mi,{children:"Q"}),(0,a.jsx)(e.mo,{separator:"true",children:","}),(0,a.jsx)(e.mi,{children:"K"}),(0,a.jsx)(e.mo,{separator:"true",children:","}),(0,a.jsx)(e.mi,{children:"V"}),(0,a.jsx)(e.mo,{stretchy:"false",children:")"}),(0,a.jsx)(e.mo,{children:"="}),(0,a.jsx)(e.mtext,{children:"softmax"}),(0,a.jsxs)(e.mrow,{children:[(0,a.jsx)(e.mo,{fence:"true",children:"("}),(0,a.jsxs)(e.mfrac,{children:[(0,a.jsxs)(e.mrow,{children:[(0,a.jsx)(e.mi,{children:"Q"}),(0,a.jsxs)(e.msup,{children:[(0,a.jsx)(e.mi,{children:"K"}),(0,a.jsx)(e.mi,{children:"T"})]})]}),(0,a.jsx)(e.msqrt,{children:(0,a.jsxs)(e.msub,{children:[(0,a.jsx)(e.mi,{children:"d"}),(0,a.jsx)(e.mi,{children:"k"})]})})]}),(0,a.jsx)(e.mo,{fence:"true",children:")"})]}),(0,a.jsx)(e.mi,{children:"V"})]}),(0,a.jsx)(e.annotation,{encoding:"application/x-tex",children:"\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V"})]})})}),(0,a.jsxs)(e.span,{className:"katex-html","aria-hidden":"true",children:[(0,a.jsxs)(e.span,{className:"base",children:[(0,a.jsx)(e.span,{className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,a.jsx)(e.span,{className:"mord text",children:(0,a.jsx)(e.span,{className:"mord",children:"Attention"})}),(0,a.jsx)(e.span,{className:"mopen",children:"("}),(0,a.jsx)(e.span,{className:"mord mathnormal",children:"Q"}),(0,a.jsx)(e.span,{className:"mpunct",children:","}),(0,a.jsx)(e.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,a.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.07153em"},children:"K"}),(0,a.jsx)(e.span,{className:"mpunct",children:","}),(0,a.jsx)(e.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,a.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.22222em"},children:"V"}),(0,a.jsx)(e.span,{className:"mclose",children:")"}),(0,a.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,a.jsx)(e.span,{className:"mrel",children:"="}),(0,a.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,a.jsxs)(e.span,{className:"base",children:[(0,a.jsx)(e.span,{className:"strut",style:{height:"2.4684em",verticalAlign:"-0.95em"}}),(0,a.jsx)(e.span,{className:"mord text",children:(0,a.jsx)(e.span,{className:"mord",children:"softmax"})}),(0,a.jsx)(e.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,a.jsxs)(e.span,{className:"minner",children:[(0,a.jsx)(e.span,{className:"mopen delimcenter",style:{top:"0em"},children:(0,a.jsx)(e.span,{className:"delimsizing size3",children:"("})}),(0,a.jsxs)(e.span,{className:"mord",children:[(0,a.jsx)(e.span,{className:"mopen nulldelimiter"}),(0,a.jsx)(e.span,{className:"mfrac",children:(0,a.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(e.span,{className:"vlist-r",children:[(0,a.jsxs)(e.span,{className:"vlist",style:{height:"1.5183em"},children:[(0,a.jsxs)(e.span,{style:{top:"-2.2528em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(e.span,{className:"mord",children:(0,a.jsx)(e.span,{className:"mord sqrt",children:(0,a.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(e.span,{className:"vlist-r",children:[(0,a.jsxs)(e.span,{className:"vlist",style:{height:"0.8572em"},children:[(0,a.jsxs)(e.span,{className:"svg-align",style:{top:"-3em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(e.span,{className:"mord",style:{paddingLeft:"0.833em"},children:(0,a.jsxs)(e.span,{className:"mord",children:[(0,a.jsx)(e.span,{className:"mord mathnormal",children:"d"}),(0,a.jsx)(e.span,{className:"msupsub",children:(0,a.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(e.span,{className:"vlist-r",children:[(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.3361em"},children:(0,a.jsxs)(e.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(e.span,{className:"mord mathnormal mtight",style:{marginRight:"0.03148em"},children:"k"})})]})}),(0,a.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(e.span,{className:"vlist-r",children:(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.15em"},children:(0,a.jsx)(e.span,{})})})]})})]})})]}),(0,a.jsxs)(e.span,{style:{top:"-2.8172em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(e.span,{className:"hide-tail",style:{minWidth:"0.853em",height:"1.08em"},children:(0,a.jsx)(e.svg,{xmlns:"http://www.w3.org/2000/svg",width:"400em",height:"1.08em",viewBox:"0 0 400000 1080",preserveAspectRatio:"xMinYMin slice",children:(0,a.jsx)(e.path,{d:"M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z"})})})]})]}),(0,a.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(e.span,{className:"vlist-r",children:(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.1828em"},children:(0,a.jsx)(e.span,{})})})]})})})]}),(0,a.jsxs)(e.span,{style:{top:"-3.23em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(e.span,{className:"frac-line",style:{borderBottomWidth:"0.04em"}})]}),(0,a.jsxs)(e.span,{style:{top:"-3.677em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsxs)(e.span,{className:"mord",children:[(0,a.jsx)(e.span,{className:"mord mathnormal",children:"Q"}),(0,a.jsxs)(e.span,{className:"mord",children:[(0,a.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.07153em"},children:"K"}),(0,a.jsx)(e.span,{className:"msupsub",children:(0,a.jsx)(e.span,{className:"vlist-t",children:(0,a.jsx)(e.span,{className:"vlist-r",children:(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.8413em"},children:(0,a.jsxs)(e.span,{style:{top:"-3.063em",marginRight:"0.05em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(e.span,{className:"mord mathnormal mtight",style:{marginRight:"0.13889em"},children:"T"})})]})})})})})]})]})]})]}),(0,a.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(e.span,{className:"vlist-r",children:(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.93em"},children:(0,a.jsx)(e.span,{})})})]})}),(0,a.jsx)(e.span,{className:"mclose nulldelimiter"})]}),(0,a.jsx)(e.span,{className:"mclose delimcenter",style:{top:"0em"},children:(0,a.jsx)(e.span,{className:"delimsizing size3",children:")"})})]}),(0,a.jsx)(e.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,a.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.22222em"},children:"V"})]})]})]})}),"\n",(0,a.jsx)(e.h3,{id:"meaning-of-terms",children:"Meaning of terms:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.code,{children:"K"})," = Key: What each word offers"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.code,{children:"V"}),' = Value: What each word "contains"']}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsxs)(e.span,{className:"katex",children:[(0,a.jsx)(e.span,{className:"katex-mathml",children:(0,a.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(e.semantics,{children:[(0,a.jsx)(e.mrow,{children:(0,a.jsxs)(e.msub,{children:[(0,a.jsx)(e.mi,{children:"d"}),(0,a.jsx)(e.mi,{children:"k"})]})}),(0,a.jsx)(e.annotation,{encoding:"application/x-tex",children:"d_k"})]})})}),(0,a.jsx)(e.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(e.span,{className:"base",children:[(0,a.jsx)(e.span,{className:"strut",style:{height:"0.8444em",verticalAlign:"-0.15em"}}),(0,a.jsxs)(e.span,{className:"mord",children:[(0,a.jsx)(e.span,{className:"mord mathnormal",children:"d"}),(0,a.jsx)(e.span,{className:"msupsub",children:(0,a.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(e.span,{className:"vlist-r",children:[(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.3361em"},children:(0,a.jsxs)(e.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(e.span,{className:"mord mathnormal mtight",style:{marginRight:"0.03148em"},children:"k"})})]})}),(0,a.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(e.span,{className:"vlist-r",children:(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.15em"},children:(0,a.jsx)(e.span,{})})})]})})]})]})})]})," = dimension of the key vector  "]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.code,{children:"softmax(...)"})," turns similarity scores into probabilities"]}),"\n"]}),"\n",(0,a.jsxs)(e.p,{children:["The scaling by ",(0,a.jsxs)(e.span,{className:"katex",children:[(0,a.jsx)(e.span,{className:"katex-mathml",children:(0,a.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(e.semantics,{children:[(0,a.jsx)(e.mrow,{children:(0,a.jsx)(e.msqrt,{children:(0,a.jsxs)(e.msub,{children:[(0,a.jsx)(e.mi,{children:"d"}),(0,a.jsx)(e.mi,{children:"k"})]})})}),(0,a.jsx)(e.annotation,{encoding:"application/x-tex",children:"\\sqrt{d_k}"})]})})}),(0,a.jsx)(e.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(e.span,{className:"base",children:[(0,a.jsx)(e.span,{className:"strut",style:{height:"1.04em",verticalAlign:"-0.1828em"}}),(0,a.jsx)(e.span,{className:"mord sqrt",children:(0,a.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(e.span,{className:"vlist-r",children:[(0,a.jsxs)(e.span,{className:"vlist",style:{height:"0.8572em"},children:[(0,a.jsxs)(e.span,{className:"svg-align",style:{top:"-3em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(e.span,{className:"mord",style:{paddingLeft:"0.833em"},children:(0,a.jsxs)(e.span,{className:"mord",children:[(0,a.jsx)(e.span,{className:"mord mathnormal",children:"d"}),(0,a.jsx)(e.span,{className:"msupsub",children:(0,a.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(e.span,{className:"vlist-r",children:[(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.3361em"},children:(0,a.jsxs)(e.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(e.span,{className:"mord mathnormal mtight",style:{marginRight:"0.03148em"},children:"k"})})]})}),(0,a.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(e.span,{className:"vlist-r",children:(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.15em"},children:(0,a.jsx)(e.span,{})})})]})})]})})]}),(0,a.jsxs)(e.span,{style:{top:"-2.8172em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(e.span,{className:"hide-tail",style:{minWidth:"0.853em",height:"1.08em"},children:(0,a.jsx)(e.svg,{xmlns:"http://www.w3.org/2000/svg",width:"400em",height:"1.08em",viewBox:"0 0 400000 1080",preserveAspectRatio:"xMinYMin slice",children:(0,a.jsx)(e.path,{d:"M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z"})})})]})]}),(0,a.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(e.span,{className:"vlist-r",children:(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.1828em"},children:(0,a.jsx)(e.span,{})})})]})})]})})]})," ensures that the dot products don\u2019t get too large, which would make softmax overly peaky (one word gets nearly all attention). "]}),"\n",(0,a.jsx)(e.hr,{}),"\n",(0,a.jsx)(e.h2,{id:"-2-what-is-multi-head-attention",children:"\ud83d\udd01 2. What Is Multi-Head Attention?"}),"\n",(0,a.jsxs)(e.blockquote,{children:["\n",(0,a.jsx)(e.p,{children:"Instead of running just one attention mechanism, we run several in parallel."}),"\n"]}),"\n",(0,a.jsx)(e.p,{children:"Each \u201chead\u201d gets its own Q, K, V matrices (via learned linear layers), allowing it to:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:["Learn ",(0,a.jsx)(e.strong,{children:"different relationships"})," (e.g., syntax, grammar, position)"]}),"\n",(0,a.jsxs)(e.li,{children:["Attend to ",(0,a.jsx)(e.strong,{children:"different tokens"})," in the same input"]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"example",children:"Example:"}),"\n",(0,a.jsx)(e.p,{children:"Suppose your input embeddings are 4-dimensional, and you use 2 heads:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Each head gets 2-dimensional Q, K, V vectors (split)"}),"\n",(0,a.jsx)(e.li,{children:"Attention is computed separately in each head"}),"\n",(0,a.jsxs)(e.li,{children:["Outputs are ",(0,a.jsx)(e.strong,{children:"concatenated"})," and passed through a final linear layer"]}),"\n"]}),"\n",(0,a.jsx)(e.p,{children:"\ud83e\udde0 This gives the model more flexibility and a richer representation."}),"\n",(0,a.jsx)(e.hr,{}),"\n",(0,a.jsx)(e.h2,{id:"\ufe0f-3-whats-a-transformer-encoder-layer",children:"\ud83c\udfd7\ufe0f 3. What\u2019s a Transformer Encoder Layer?"}),"\n",(0,a.jsxs)(e.p,{children:["Each ",(0,a.jsx)(e.strong,{children:"encoder layer"})," in a Transformer consists of:"]}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Multi-head self-attention"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Input goes through multiple attention heads"}),"\n",(0,a.jsx)(e.li,{children:"The output is context-aware embeddings"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Add & Norm"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Add the original input (residual connection)"}),"\n",(0,a.jsx)(e.li,{children:"Normalize the result (layer normalization)"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Feed-forward Network (FFN)"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"A linear \u2192 activation \u2192 linear block applied to each position"}),"\n",(0,a.jsx)(e.li,{children:"Adds extra non-linearity"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Add & Norm again"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Another residual + normalization"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(e.p,{children:["You can ",(0,a.jsx)(e.strong,{children:"stack"})," multiple encoder layers to allow deeper understanding of patterns."]}),"\n",(0,a.jsx)(e.hr,{}),"\n",(0,a.jsx)(e.h2,{id:"-4-what-about-transformers-for-translation",children:"\ud83e\udde9 4. What About Transformers for Translation?"}),"\n",(0,a.jsxs)(e.p,{children:["In ",(0,a.jsx)(e.strong,{children:"translation"}),", we use:"]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Encoder"}),": Processes the source sentence (e.g., French)"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Decoder"}),": Generates the target sentence (e.g., English)"]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"decoder-specialties",children:"Decoder Specialties:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:["Uses ",(0,a.jsx)(e.strong,{children:"masked self-attention"})," to prevent cheating (no peeking at future words)"]}),"\n",(0,a.jsxs)(e.li,{children:["Uses ",(0,a.jsx)(e.strong,{children:"cross-attention"}),": queries come from the decoder, but keys and values come from the encoder output"]}),"\n"]}),"\n",(0,a.jsx)(e.hr,{}),"\n",(0,a.jsx)(e.h2,{id:"-5-how-do-you-build-this-in-pytorch",children:"\ud83d\udd27 5. How Do You Build This in PyTorch?"}),"\n",(0,a.jsx)(e.h3,{id:"multihead-attention",children:"Multihead Attention"}),"\n",(0,a.jsx)(e.h1,{id:"removed-python-copyedit-as-its-not-part-of-the-code",children:'Removed "python CopyEdit" as it\'s not part of the code'}),"\n",(0,a.jsx)(e.p,{children:"attention = nn.MultiheadAttention(embed_dim=4, num_heads=2, batch_first=False)\noutput, weights = attention(Q, K, V)"}),"\n",(0,a.jsx)(e.h1,{id:"removed-python-copyedit",children:'Removed "python CopyEdit"'}),"\n",(0,a.jsx)(e.p,{children:"encoder_layer = nn.TransformerEncoderLayer(d_model=4, nhead=2)\ntransformer = nn.TransformerEncoder(encoder_layer, num_layers=2)"}),"\n",(0,a.jsx)(e.p,{children:"x = torch.rand(seq_len, batch_size, embed_dim) # Assuming these vars are defined elsewhere\nout = transformer(x)"}),"\n",(0,a.jsx)(e.p,{children:"Each layer will apply:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Multi-head attention"}),"\n",(0,a.jsx)(e.li,{children:"Add & Norm"}),"\n",(0,a.jsx)(e.li,{children:"Feedforward"}),"\n",(0,a.jsx)(e.li,{children:"Add & Norm again"}),"\n"]}),"\n",(0,a.jsx)(e.hr,{}),"\n",(0,a.jsx)(e.h2,{id:"-6-recap",children:"\ud83c\udfaf 6. Recap"}),"\n",(0,a.jsxs)(e.table,{children:[(0,a.jsx)(e.thead,{children:(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.th,{children:"Concept"}),(0,a.jsx)(e.th,{children:"Key Idea"})]})}),(0,a.jsxs)(e.tbody,{children:[(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:(0,a.jsx)(e.strong,{children:"Attention"})}),(0,a.jsx)(e.td,{children:"Focuses on important words via dot-product"})]}),(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:(0,a.jsx)(e.strong,{children:"Scaled Dot Product"})}),(0,a.jsx)(e.td,{children:"Softmax on similarity scores, scaled by \u221ad\u2096"})]}),(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:(0,a.jsx)(e.strong,{children:"Multi-Head Attention"})}),(0,a.jsx)(e.td,{children:"Parallel attention heads learn different patterns"})]}),(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:(0,a.jsx)(e.strong,{children:"Encoder"})}),(0,a.jsx)(e.td,{children:"Stacks attention + FFN with normalization"})]}),(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:(0,a.jsx)(e.strong,{children:"Decoder"})}),(0,a.jsx)(e.td,{children:"Adds masking and cross-attention"})]}),(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:(0,a.jsx)(e.strong,{children:"Transformers"})}),(0,a.jsx)(e.td,{children:"Stack layers \u2192 deeper representations"})]})]})]})]})}function m(s={}){const{wrapper:e}={...(0,l.R)(),...s.components};return e?(0,a.jsx)(e,{...s,children:(0,a.jsx)(h,{...s})}):h(s)}},8453:(s,e,n)=>{n.d(e,{R:()=>i,x:()=>r});var t=n(6540);const a={},l=t.createContext(a);function i(s){const e=t.useContext(l);return t.useMemo((function(){return"function"==typeof s?s(e):{...e,...s}}),[e,s])}function r(s){let e;return e=s.disableParentContext?"function"==typeof s.components?s.components(a):s.components||a:i(s.components),t.createElement(l.Provider,{value:e},s.children)}}}]);