"use strict";(self.webpackChunkxuecodex=self.webpackChunkxuecodex||[]).push([[2522],{4453:e=>{e.exports=JSON.parse('{"tag":{"label":"transformers","permalink":"/docs/tags/transformers","allTagsPath":"/docs/tags","count":5,"items":[{"id":"topics/deep-learning/nlp/attentoin-mechanism","title":"Attention Mechanism \u2014 A Gentle but Deep Dive","description":"1\ufe0f\u20e3 What Is the Attention Mechanism and Why Is It Important?","permalink":"/docs/topics/deep-learning/nlp/attentoin-mechanism"},{"id":"topics/deep-learning/nlp/Multi-head attention","title":"Multihead Attention","description":"\ud83e\udde0 1. What Is Scaled Dot-Product Attention?","permalink":"/docs/topics/deep-learning/nlp/Multi-head attention"},{"id":"topics/deep-learning/nlp/transformer-architecture","title":"Transformer Architecture ","description":"---","permalink":"/docs/topics/deep-learning/nlp/transformer-architecture"},{"id":"topics/deep-learning/nlp/transformer-attention","title":"Transformers and Attention \u2013 Explained with Visuals","description":"---","permalink":"/docs/topics/deep-learning/nlp/transformer-attention"},{"id":"topics/deep-learning/nlp/self-attention","title":"What Is Self-Attention?","description":"Self-attention allows a model to look at all the other words in a sentence (or a document, or code...) and decide how important each of them is for understanding a particular word.","permalink":"/docs/topics/deep-learning/nlp/self-attention"}],"unlisted":false}}')}}]);