<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-topics/deep-learning/neural-networks" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">What are Neural Networks? | XueCodex</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://xuecodex.tech/img/xuecodex-social.png"><meta data-rh="true" name="twitter:image" content="https://xuecodex.tech/img/xuecodex-social.png"><meta data-rh="true" property="og:url" content="https://xuecodex.tech/docs/topics/deep-learning/neural-networks"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="What are Neural Networks? | XueCodex"><meta data-rh="true" name="description" content="Understanding Neural Networks, Weights, and Stochastic Gradient Descent"><meta data-rh="true" property="og:description" content="Understanding Neural Networks, Weights, and Stochastic Gradient Descent"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://xuecodex.tech/docs/topics/deep-learning/neural-networks"><link data-rh="true" rel="alternate" href="https://xuecodex.tech/docs/topics/deep-learning/neural-networks" hreflang="en"><link data-rh="true" rel="alternate" href="https://xuecodex.tech/docs/topics/deep-learning/neural-networks" hreflang="x-default"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css" integrity="sha384-mll67QQo1R+Vg3FoYAZ9uTzB8S3DFAP1nQFZ/foqg8IjrCSw56mQBiOkR1C+Xni1" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.30bfeeb7.css">
<script src="/assets/js/runtime~main.99f7777c.js" defer="defer"></script>
<script src="/assets/js/main.ad16aa94.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/logo.png"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top navbar--dark"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.png" alt="XueCodex Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.png" alt="XueCodex Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">XueCodex</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/progress/progress">Docs</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/vlakmaker/XueCodex" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS darkNavbarColorModeToggle_X3D1" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite" aria-pressed="false"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/progress/progress">Progress Log</a><button aria-label="Expand sidebar category &#x27;Progress Log&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro">Welcome to XueCodex</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/projects/prompt-engineering-categories">projects</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/docs/topics/ai-fundamentals">topics</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/topics/ai-fundamentals">AI Fundamentals</a><button aria-label="Expand sidebar category &#x27;AI Fundamentals&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" tabindex="0" href="/docs/topics/machine-learning/binary-classification">Machine Learning</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/topics/machine-learning/binary-classification">Binary Classification and Associated Concepts</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/topics/machine-learning/broadcasting-python">Broadcasting in Python and Deep Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/topics/machine-learning/computation-derivatives">Computing Derivatives with a Computation Graph</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/topics/machine-learning/computation-graph">Computation Graphs – Visualizing How Functions Wor</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/topics/machine-learning/derivatives">Understanding Derivatives Visually: The Curve of f(x) = x^2</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/topics/machine-learning/f-b-propagation">Training a Neural Network: Forward and Backpropagation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/topics/machine-learning/logistic-regression-cost-function">Logistic Regression Cost Function</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/topics/machine-learning/logistic-regression-derivatives">Logistic Regression Derivatives (Simple Explanation)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/topics/machine-learning/logistic-regression">Logistic Regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/topics/machine-learning/machine-learning-limitations">Machine Learning Limitation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/topics/machine-learning/training-process-of-ml">Understanding the Training Process of a Machine Learning Model</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/topics/machine-learning/vectorizing-logistic-regression">Vectorizing Logistic Regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/topics/machine-learning/what-is-machine-learning">What is Machine Learning</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/docs/topics/deep-learning/activation-functions-derivatives">Deep Learning</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/topics/deep-learning/activation-functions-derivatives">Activation Functions &amp; Derivatives</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/topics/deep-learning/activation-functions">Activation Functions for Humans: Sigmoid, Tanh, and ReLU (Deep Dive)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/topics/deep-learning/drivetrain-approach">The Drivetrain Approach: A Strategic Framework for AI Development</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/topics/deep-learning/neural-network-forward-pass">Neural Network Forward Pass</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/topics/deep-learning/object-detection-data-augmentation">What is Object Detection &amp; Data Augmentation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/topics/deep-learning/rag-introduction">rag-introduction</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/topics/deep-learning/weight-initialization">Weight Initialization in Neural Networks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/topics/deep-learning/weights">weights</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/topics/deep-learning/neural-networks">What are Neural Networks?</a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/topics/ai-engineering">AI Engineering</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/topics/ai-storytelling">AI Storytelling</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/topics/product-management">AI Product Management</a><button aria-label="Expand sidebar category &#x27;AI Product Management&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/topics/prompt-engineering">Prompt Engineering</a><button aria-label="Expand sidebar category &#x27;Prompt Engineering&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">topics</span><meta itemprop="position" content="1"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Deep Learning</span><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">What are Neural Networks?</span><meta itemprop="position" content="3"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Neural Networks</h1></header>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="understanding-neural-networks-weights-and-stochastic-gradient-descent">Understanding Neural Networks, Weights, and Stochastic Gradient Descent<a href="#understanding-neural-networks-weights-and-stochastic-gradient-descent" class="hash-link" aria-label="Direct link to Understanding Neural Networks, Weights, and Stochastic Gradient Descent" title="Direct link to Understanding Neural Networks, Weights, and Stochastic Gradient Descent">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="what-are-neural-networks">What Are Neural Networks?<a href="#what-are-neural-networks" class="hash-link" aria-label="Direct link to What Are Neural Networks?" title="Direct link to What Are Neural Networks?">​</a></h3>
<p>A <strong>neural network</strong> is a type of machine learning model inspired by the way human brains process information. It consists of layers of artificial neurons that take in data, process it, and produce an output. These networks are used for a variety of tasks, including image recognition, language translation, and even playing games.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="how-a-neural-network-works">How a Neural Network Works<a href="#how-a-neural-network-works" class="hash-link" aria-label="Direct link to How a Neural Network Works" title="Direct link to How a Neural Network Works">​</a></h4>
<p>Think of a neural network as a team of detectives solving a case:</p>
<ul>
<li>Each detective (neuron) gathers clues (input data).</li>
<li>They communicate with each other, refining the information (hidden layers).</li>
<li>Finally, they determine who the culprit is (output layer).</li>
</ul>
<p>Just like a detective team might adjust their level of trust in different sources, a neural network adjusts the &quot;importance&quot; of different inputs. This is where <strong>weights</strong> come in.</p>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="what-are-weights-in-a-neural-network">What Are Weights in a Neural Network?<a href="#what-are-weights-in-a-neural-network" class="hash-link" aria-label="Direct link to What Are Weights in a Neural Network?" title="Direct link to What Are Weights in a Neural Network?">​</a></h3>
<p>Weights are the <strong>key decision-making factors</strong> in a neural network. They determine how much influence an input has on the final prediction.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="example-house-price-prediction">Example: House Price Prediction<a href="#example-house-price-prediction" class="hash-link" aria-label="Direct link to Example: House Price Prediction" title="Direct link to Example: House Price Prediction">​</a></h4>
<p>Imagine you&#x27;re predicting house prices based on three factors:</p>
<ol>
<li>Size of the house</li>
<li>Number of bedrooms</li>
<li>Location</li>
</ol>
<p>Each of these factors contributes differently to the final price. If location is the most important, it should have the highest <strong>weight</strong>. The formula might look something like this:</p>
<p>Price = 0.3 * Size + 0.2 * Bedrooms + 0.5 * Location</p>
<p>Here, <strong>0.3, 0.2, and 0.5</strong> are the weights, showing how much each factor influences the price. The model learns these weights by trial and error, improving them over time through <strong>training</strong>.</p>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="how-weights-are-determined">How Weights Are Determined<a href="#how-weights-are-determined" class="hash-link" aria-label="Direct link to How Weights Are Determined" title="Direct link to How Weights Are Determined">​</a></h3>
<p>At first, the network assigns random weights. Then, it makes a prediction and checks how far it is from the correct answer. The model then adjusts the weights slightly to make the prediction more accurate next time.</p>
<p>This process repeats thousands (or millions) of times until the weights are <strong>optimized</strong>. The goal is to minimize the error as much as possible.</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="stochastic-gradient-descent-sgd-how-the-model-learns">Stochastic Gradient Descent (SGD): How the Model Learns<a href="#stochastic-gradient-descent-sgd-how-the-model-learns" class="hash-link" aria-label="Direct link to Stochastic Gradient Descent (SGD): How the Model Learns" title="Direct link to Stochastic Gradient Descent (SGD): How the Model Learns">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="understanding-the-concept-climbing-down-a-mountain">Understanding the Concept: Climbing Down a Mountain<a href="#understanding-the-concept-climbing-down-a-mountain" class="hash-link" aria-label="Direct link to Understanding the Concept: Climbing Down a Mountain" title="Direct link to Understanding the Concept: Climbing Down a Mountain">​</a></h3>
<p>Imagine you are standing on top of a mountain, blindfolded, trying to find the lowest point in the valley. You take small steps downhill, checking each time if you’re getting lower. If yes, you continue in that direction. If not, you change course.</p>
<p>This is exactly how <strong>Stochastic Gradient Descent (SGD)</strong> works:</p>
<ol>
<li>It looks at the current prediction error.</li>
<li>It calculates how much the weights need to change.</li>
<li>It takes a small step (adjusting weights slightly).</li>
<li>It repeats until the error is as small as possible.</li>
</ol>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="breaking-down-the-process">Breaking Down the Process<a href="#breaking-down-the-process" class="hash-link" aria-label="Direct link to Breaking Down the Process" title="Direct link to Breaking Down the Process">​</a></h3>
<ol>
<li><strong>Forward Propagation</strong> – Data passes through the network, and a prediction is made.</li>
<li><strong>Loss Calculation</strong> – The model compares the prediction with the actual answer (error is calculated).</li>
<li><strong>Backpropagation</strong> – The model figures out how to change the weights to reduce the error.</li>
<li><strong>Weight Update (Gradient Descent)</strong> – The weights are adjusted slightly in the correct direction.</li>
<li><strong>Repeat</strong> – The process continues until the model becomes highly accurate.</li>
</ol>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="why-stochastic-gradient-descent">Why Stochastic Gradient Descent?<a href="#why-stochastic-gradient-descent" class="hash-link" aria-label="Direct link to Why Stochastic Gradient Descent?" title="Direct link to Why Stochastic Gradient Descent?">​</a></h2>
<p>The term <strong>stochastic</strong> means “random.” Instead of looking at all the data at once, SGD picks small random samples, making learning faster and more efficient. It avoids getting stuck in bad solutions and helps the model learn in a way that works well for large datasets.</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="summary-of-key-concepts">Summary of Key Concepts<a href="#summary-of-key-concepts" class="hash-link" aria-label="Direct link to Summary of Key Concepts" title="Direct link to Summary of Key Concepts">​</a></h2>
<ul>
<li><strong>Neural Networks</strong>: Systems that learn patterns from data, similar to human brains.</li>
<li><strong>Weights</strong>: Numbers that determine how much influence an input has on the final prediction.</li>
<li><strong>Gradient Descent</strong>: A method for adjusting weights to reduce errors.</li>
<li><strong>Stochastic Gradient Descent (SGD)</strong>: A faster way of updating weights using small random samples of data.</li>
</ul>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="final-analogy-making-the-perfect-cup-of-coffee">Final Analogy: Making the Perfect Cup of Coffee<a href="#final-analogy-making-the-perfect-cup-of-coffee" class="hash-link" aria-label="Direct link to Final Analogy: Making the Perfect Cup of Coffee" title="Direct link to Final Analogy: Making the Perfect Cup of Coffee">​</a></h3>
<p>Think of training a neural network like perfecting a coffee recipe:</p>
<ol>
<li>You start with random amounts of coffee, water, and sugar (random weights).</li>
<li>You take a sip and realize it&#x27;s too bitter (error calculation).</li>
<li>You adjust the sugar and water slightly (gradient descent updates weights).</li>
<li>You keep tweaking until the taste is just right (minimized error).</li>
</ol>
<p>With this process, the model (or the coffee) keeps getting better over time!</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-tags-row"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/machine-learning">machine-learning</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/deep-learning">deep learning</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/neural-networks">neural networks</a></li></ul></div></div><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/vlakmaker/XueCodex/tree/main/docs/topics/deep-learning/what-are-neural-networks.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/topics/deep-learning/weights"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">weights</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/topics/ai-engineering"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">AI Engineering</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#understanding-neural-networks-weights-and-stochastic-gradient-descent" class="table-of-contents__link toc-highlight">Understanding Neural Networks, Weights, and Stochastic Gradient Descent</a><ul><li><a href="#what-are-neural-networks" class="table-of-contents__link toc-highlight">What Are Neural Networks?</a></li><li><a href="#what-are-weights-in-a-neural-network" class="table-of-contents__link toc-highlight">What Are Weights in a Neural Network?</a></li><li><a href="#how-weights-are-determined" class="table-of-contents__link toc-highlight">How Weights Are Determined</a></li></ul></li><li><a href="#stochastic-gradient-descent-sgd-how-the-model-learns" class="table-of-contents__link toc-highlight">Stochastic Gradient Descent (SGD): How the Model Learns</a><ul><li><a href="#understanding-the-concept-climbing-down-a-mountain" class="table-of-contents__link toc-highlight">Understanding the Concept: Climbing Down a Mountain</a></li><li><a href="#breaking-down-the-process" class="table-of-contents__link toc-highlight">Breaking Down the Process</a></li></ul></li><li><a href="#why-stochastic-gradient-descent" class="table-of-contents__link toc-highlight">Why Stochastic Gradient Descent?</a></li><li><a href="#summary-of-key-concepts" class="table-of-contents__link toc-highlight">Summary of Key Concepts</a><ul><li><a href="#final-analogy-making-the-perfect-cup-of-coffee" class="table-of-contents__link toc-highlight">Final Analogy: Making the Perfect Cup of Coffee</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/topics/ai-fundamentals/what-is-ai">AI Fundamentals</a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/vlakmaker/XueCodex" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 XueCodex. Built with 💙 & Docusaurus.</div></div></div></footer></div>
</body>
</html>