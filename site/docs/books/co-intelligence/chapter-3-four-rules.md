---
id: chapter-3-four-rules
title: Four Rules for Co-Intelligence
tags: [books, mollick, co-intelligence, prompting, personas, human-ai, principles]
---

# ğŸ¤ Co-Intelligence â€“ Chapter 3: Four Rules for Co-Intelligence

## ğŸ“˜ Summary

Chapter 3 of *Co-Intelligence* introduces four foundational **principles** for interacting effectively with modern AI systems. These â€œrulesâ€ are framed as **timeless interaction patterns** that transcend any single AI tool or interface, offering guidance for human-AI collaboration across evolving platforms.

The centerpiece is **Rule 3: â€œTreat AI like a person (but tell it what kind of person it is).â€** Ethan Mollick adopts this intentionally anthropomorphic framing throughout the bookâ€”not because AIs have thoughts or feelings, but because it **helps users engage with LLMs more productively** by defining their â€œroleâ€ in the conversation.

---

## ğŸ§© Key Rules of Co-Intelligence

### 1. ğŸ¤– Rule: *Invite AI to Everything*

- Get used to integrating AI into your workflows early and often.
- Even if the results arenâ€™t perfect, including AI helps map the **â€œJagged Frontierâ€**â€”the unpredictable boundary between tasks AI can do well and those it canâ€™t.
- Think like a **Centaur**: combine your strengths with AIâ€™s to achieve better results.

### 2. ğŸ’¬ Rule: *Ask the AI to Explain Itself*

- AI can reason and reflect (within limits) if prompted correctly.
- Asking it to list, critique, and explain before making a conclusion leads to **richer and more thoughtful output**.
- Using structured reasoning processes in your prompt improves both the **quality and transparency** of responses.

### 3. ğŸ§  Rule: *Treat the AI Like a Person (But Tell It What Kind of Person)*

- While AIs arenâ€™t sentient, they simulate human behavior convincingly through language.
- **Personas matter**: define the AIâ€™s role, tone, or expertise in the prompt for better results.
  - Example: â€œYou are a thoughtful tutorâ€ yields much better results than a generic query.
- Prompt engineering helps override the LLMâ€™s default patterns and status quo bias.
- This principle **unlocks creativity, clarity, and adaptability** from the model.

### 4. ğŸ§ª Rule: *Use AI to Think Differently, Not Just to Do Things Faster*

- The real power of AI isnâ€™t just automationâ€”itâ€™s **ideation and exploration**.
- Use AI to brainstorm, reframe problems, generate edge cases, and stress-test assumptions.
- AI is a **collaborative thinking partner**, not just a productivity tool.

---

## ğŸ§  Key Insight

> **Treating an AI like a helpful human (with the right instructions) allows us to collaborate more effectively. Prompt design is how we define the relationship.**

AI doesnâ€™t know what role it should play unless we tell it. Giving it **structured instructions, personality traits, or perspectives** makes it easier to get meaningful results.

---

## ğŸ’¡ Practical Prompting Example

**Bad Prompt:**  
> â€œGive me a good analogy for an AI tutor.â€

**Good Prompt (Structured Prompting + Persona):**  
> â€œYou are an expert in education psychology. First, list 5 possible analogies for how an AI tutor might help students. Then critique each analogy. Add more if needed. Select the best one, and explain why.â€

**Result:**  
> A compelling analogy comparing AI tutors to GPS systemsâ€”guiding, not driving; assisting, not replacing.

---

## ğŸ“ Risks & Considerations

- **Hallucinations**: AI may still confidently give incorrect answers.
- **Bias**: LLMs often mirror their training data and exhibit **status quo bias**.
- **Flattery or â€œpleasing the userâ€**: AI may prioritize agreement over accuracy.
- **Over-reliance**: Donâ€™t assume correctness because the output â€œsounds smart.â€
